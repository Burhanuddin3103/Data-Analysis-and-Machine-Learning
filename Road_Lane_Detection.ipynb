{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHQH-ZFHh8ji",
        "outputId": "6639cede-53ae-4117-b4d7-471208d40de2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from moviepy.editor import VideoFileClip\n",
        "from moviepy import *\n",
        "from IPython.display import HTML\n",
        "from IPython.display import Image\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysbpO5l4j7I2"
      },
      "outputs": [],
      "source": [
        "def list_images(images, cols = 2, rows = 5, cmap=None):\n",
        "    \n",
        "    plt.figure(figsize=(10, 11))\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        cmap = 'gray' if len(image.shape) == 2 else cmap\n",
        "        plt.imshow(image, cmap = cmap)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfLFngn0kHGu"
      },
      "outputs": [],
      "source": [
        "def RGB_color_selection(image):\n",
        "\n",
        "    lower_threshold = np.uint8([200, 200, 200])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
        "    \n",
        "\n",
        "    lower_threshold = np.uint8([175, 175,   0])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    yellow_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
        "    \n",
        "\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "    \n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrByPyY3kH3A"
      },
      "outputs": [],
      "source": [
        "def convert_hsv(image):\n",
        "    \n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnyLAa0xkIBH"
      },
      "outputs": [],
      "source": [
        "def HSV_color_selection(image):\n",
        "\n",
        "    converted_image = convert_hsv(image)\n",
        "\n",
        "\n",
        "    lower_threshold = np.uint8([0, 0, 210])\n",
        "    upper_threshold = np.uint8([255, 30, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "\n",
        "    lower_threshold = np.uint8([18, 80, 80])\n",
        "    upper_threshold = np.uint8([30, 255, 255])\n",
        "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "    \n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m7bnmH6kIM_"
      },
      "outputs": [],
      "source": [
        "def convert_hsl(image):\n",
        "   \n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_oEJ-w4xfyZ"
      },
      "outputs": [],
      "source": [
        "def HSL_color_selection(image):\n",
        "\n",
        "    converted_image = convert_hsl(image)\n",
        "    \n",
        "\n",
        "    lower_threshold = np.uint8([0, 200, 0])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "\n",
        "    lower_threshold = np.uint8([10, 0, 100])\n",
        "    upper_threshold = np.uint8([40, 255, 255])\n",
        "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "    \n",
        "\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "    \n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfiEUvOBxf4C"
      },
      "outputs": [],
      "source": [
        "def gray_scale(image):\n",
        "    \n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHCLcAuDxf6e"
      },
      "outputs": [],
      "source": [
        "def gaussian_smoothing(image, kernel_size = 13):\n",
        "   \n",
        "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOFMK3Ftxf8_"
      },
      "outputs": [],
      "source": [
        "def canny_detector(image, low_threshold = 50, high_threshold = 150):\n",
        "    \n",
        "    return cv2.Canny(image, low_threshold, high_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs6V6qRYxf_Z"
      },
      "outputs": [],
      "source": [
        "def region_selection(image):\n",
        "    \n",
        "    mask = np.zeros_like(image)   \n",
        "    if len(image.shape) > 2:\n",
        "        channel_count = image.shape[2]\n",
        "        ignore_mask_color = (255,) * channel_count\n",
        "    else:\n",
        "        ignore_mask_color = 255\n",
        "    rows, cols = image.shape[:2]\n",
        "    bottom_left  = [cols * 0.1, rows * 0.95]\n",
        "    top_left     = [cols * 0.4, rows * 0.6]\n",
        "    bottom_right = [cols * 0.9, rows * 0.95]\n",
        "    top_right    = [cols * 0.6, rows * 0.6]\n",
        "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
        "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
        "    masked_image = cv2.bitwise_and(image, mask)\n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMjcjmjIxgB0"
      },
      "outputs": [],
      "source": [
        "def hough_transform(image):\n",
        "\n",
        "    rho = 1           \n",
        "    theta = np.pi/180    \n",
        "    threshold = 20      \n",
        "    minLineLength = 20   \n",
        "    maxLineGap = 300    \n",
        "    return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = threshold,\n",
        "                           minLineLength = minLineLength, maxLineGap = maxLineGap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMCRdS1QxgEC"
      },
      "outputs": [],
      "source": [
        "def draw_lines(image, lines, color = [255, 0, 0], thickness = 2):\n",
        "\n",
        "    image = np.copy(image)\n",
        "    for line in lines:\n",
        "        for x1,y1,x2,y2 in line:\n",
        "            cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JntYRsNGyDfN"
      },
      "outputs": [],
      "source": [
        "def average_slope_intercept(lines):\n",
        "\n",
        "    left_lines    = []\n",
        "    left_weights  = [] \n",
        "    right_lines   = [] \n",
        "    right_weights = [] \n",
        "    \n",
        "    for line in lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            if x1 == x2:\n",
        "                continue\n",
        "            slope = (y2 - y1) / (x2 - x1)\n",
        "            intercept = y1 - (slope * x1)\n",
        "            length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))\n",
        "            if slope < 0:\n",
        "                left_lines.append((slope, intercept))\n",
        "                left_weights.append((length))\n",
        "            else:\n",
        "                right_lines.append((slope, intercept))\n",
        "                right_weights.append((length))\n",
        "    left_lane  = np.dot(left_weights,  left_lines) / np.sum(left_weights)  if len(left_weights) > 0 else None\n",
        "    right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None\n",
        "    return left_lane, right_lane\n",
        "\n",
        "def pixel_points(y1, y2, line):\n",
        "\n",
        "    if line is None:\n",
        "        return None\n",
        "    slope, intercept = line\n",
        "    x1 = int((y1 - intercept)/slope)\n",
        "    x2 = int((y2 - intercept)/slope)\n",
        "    y1 = int(y1)\n",
        "    y2 = int(y2)\n",
        "    return ((x1, y1), (x2, y2))\n",
        "\n",
        "def lane_lines(image, lines):\n",
        "\n",
        "    left_lane, right_lane = average_slope_intercept(lines)\n",
        "    y1 = image.shape[0]\n",
        "    y2 = y1 * 0.6\n",
        "    left_line  = pixel_points(y1, y2, left_lane)\n",
        "    right_line = pixel_points(y1, y2, right_lane)\n",
        "    return left_line, right_line\n",
        "\n",
        "    \n",
        "def draw_lane_lines(image, lines, color=[255, 0, 0], thickness=12):\n",
        "\n",
        "    line_image = np.zeros_like(image)\n",
        "    for line in lines:\n",
        "        if line is not None:\n",
        "            cv2.line(line_image, *line,  color, thickness)\n",
        "    return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXnezulNyDh-"
      },
      "outputs": [],
      "source": [
        "def frame_processor(image):\n",
        "\n",
        "    color_select = HSL_color_selection(image)\n",
        "    gray         = gray_scale(color_select)\n",
        "    smooth       = gaussian_smoothing(gray)\n",
        "    edges        = canny_detector(smooth)\n",
        "    region       = region_selection(edges)\n",
        "    hough        = hough_transform(region)\n",
        "    result       = draw_lane_lines(image, lane_lines(image, hough))\n",
        "    return result \n",
        "    \n",
        "def process_video(test_video, output_video):\n",
        "\n",
        "    input_video = VideoFileClip(os.path.join('test_videos', test_video), audio=False)\n",
        "    processed = input_video.fl_image(frame_processor)\n",
        "    processed.write_videofile(os.path.join('output_videos', output_video), audio=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EveO671zyDkd"
      },
      "outputs": [],
      "source": [
        "test_images = [plt.imread(img) for img in glob.glob('test_images/*.jpg')]\n",
        "list_images(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmre0fWU4L6s"
      },
      "outputs": [],
      "source": [
        "list_images(list(map(RGB_color_selection, test_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsKgN3mC4h9q"
      },
      "outputs": [],
      "source": [
        "list_images(list(map(convert_hsv, test_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twTpiHn84iBU"
      },
      "outputs": [],
      "source": [
        "list_images(list(map(HSV_color_selection, test_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1clS8Qj4iIA"
      },
      "outputs": [],
      "source": [
        "list_images(list(map(convert_hsl, test_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ9eOQov4iNA"
      },
      "outputs": [],
      "source": [
        "list_images(list(map(HSL_color_selection, test_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDYNyKBH4pwT"
      },
      "outputs": [],
      "source": [
        "color_selected_images = list(map(HSL_color_selection, test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af-wxsyb3pCu"
      },
      "outputs": [],
      "source": [
        "gray_images = list(map(gray_scale, color_selected_images))\n",
        "list_images(gray_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd8WbHK23pWj"
      },
      "outputs": [],
      "source": [
        "blur_images = list(map(gaussian_smoothing, gray_images))\n",
        "list_images(blur_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJyXvKl53pZT"
      },
      "outputs": [],
      "source": [
        "edge_detected_images = list(map(canny_detector, blur_images))\n",
        "list_images(edge_detected_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0jVjfkt31jl"
      },
      "outputs": [],
      "source": [
        "masked_image = list(map(region_selection, edge_detected_images))\n",
        "list_images(masked_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMv_lo1g31nC"
      },
      "outputs": [],
      "source": [
        "hough_lines = list(map(hough_transform, masked_image))\n",
        "\n",
        "\n",
        "line_images = []\n",
        "for image, lines in zip(test_images, hough_lines):\n",
        "    line_images.append(draw_lines(image, lines))\n",
        "list_images(line_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTCuz-0631rS"
      },
      "outputs": [],
      "source": [
        "lane_images = []\n",
        "for image, lines in zip(test_images, hough_lines):\n",
        "    lane_images.append(draw_lane_lines(image, lane_lines(image, lines)))\n",
        "list_images(lane_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978,
          "resources": {
            "http://localhost:8080/output_videos/challenge_output.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "IUDjpGYVyDmr",
        "outputId": "0a1c799c-9ed3-44c3-b99f-c7c7d9b5cedc"
      },
      "outputs": [],
      "source": [
        "%time process_video('solidWhiteRight.mp4', 'solidWhiteRight_output.mp4')\n",
        "HTML(\"\"\"\n",
        "<video width=\"960\" height=\"540\" controls>\n",
        "  <source src=\"{0}\">\n",
        "</video>\n",
        "\"\"\".format(\"output_videos\\solidWhiteRight_output.mp4\"))\n",
        "\n",
        "\n",
        "%time process_video('solidYellowLeft.mp4', 'solidYellowLeft_output.mp4')\n",
        "HTML(\"\"\"\n",
        "<video width=\"960\" height=\"540\" controls>\n",
        "  <source src=\"{0}\">\n",
        "</video>\n",
        "\"\"\".format(\"output_videos\\solidYellowLeft_output.mp4\"))\n",
        "\n",
        "\n",
        "%time process_video('challenge.mp4', 'challenge_output.mp4')\n",
        "HTML(\"\"\"\n",
        "<video width=\"960\" height=\"540\" controls>\n",
        "  <source src=\"{0}\">\n",
        "</video>\n",
        "\"\"\".format(\"output_videos\\challenge_output.mp4\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Road Lane Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
